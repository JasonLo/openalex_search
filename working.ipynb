{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP author search with OpenAlex data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal is to return at author (and institution level) from a given search query.\n",
    "\n",
    "### Groupby and aggregate\n",
    "\n",
    "Borrowing/Stealing? the design language from pandas, let's think about `groupby` and `aggregate`.\n",
    "\n",
    "- groupby: defines the return object level (`author` for now)\n",
    "- aggregate: what formula we will use to `reduce` multiple records into a single metric. For example:\n",
    "    - basic count of hits\n",
    "    - custom `reranker` borrowing from retrival augmented generation (RAG) field, we weights the things that people like to see to obtain a score. More specifically, we can obtain the `cited_by_count` in each relevant paper and sum all within an author.\n",
    "    - `reranker` can also sources form multiple underlying metrics like what we do in [faculty search](https://github.com/UW-Madison-DSI/faculty-search/blob/eff2ecfedcf5e817e70e3f3541b91d4cceeabb27/api/core.py#L387)\n",
    "\n",
    "TODOs:\n",
    "\n",
    "1. Make a MVP groupby aggregate interface for search with base hit counts\n",
    "1. Implement faculty search `reranker` into aggregate\n",
    "\n",
    "\n",
    "Mock Interface \n",
    "\n",
    "```python\n",
    "search_results = search(\"effect of fungicide on corn\")\n",
    "search_results.groupby(\"author\").aggregate(\"count\")  # Hit Counts, return authors\n",
    "search_results.groupby(\"institution\").aggregate(\"count\")  # Hit Counts, return institute\n",
    "search_results.groupby(\"author\").aggregate(\"reranker_v0\")  # Fully custom reranker, return author\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openalex_search.search import search  # TODO: fix this messy deep import\n",
    "\n",
    "# This is a simple example of the core of groupby(\"author\").aggregate(\"count\")\n",
    "search(\"higgs boson\", top_k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openalex_search.db import Work\n",
    "\n",
    "w = Work.pull(doi=\"10.1111/j.1469-8986.1995.tb02956.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: The N400 as a function of the level of processing\n",
      "journal:Psychophysiology\n",
      "abstract: ABSTRACT In a semantic priming paradigm, the effects of different levels of processing on the N400 were assessed by changing the task demands. In the lexical decision task, subjects had to discriminate between words and nonwords and in the physical task, subjects had to discriminate between uppercase and lowercase letters. The proportion of related versus unrelated word pairs differed between conditions. A lexicality test on reaction times demonstrated that the physical task was performed nonlexically. Moreover, a semantic priming reaction time effect was obtained only in the lexical decision task. The level of processing clearly affected the event‚Äêrelated potentials. An N400 priming effect was only observed in the lexical decision task. In contrast, in the physical task a P300 effect was observed for either related or unrelated targets, depending on their frequency of occurrence. Taken together, the results indicate that an N400 priming effect is only evoked when the task performance induces the semantic aspects of words to become part of an episodic trace of the stimulus event.\n"
     ]
    }
   ],
   "source": [
    "print(str(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlmodel import SQLModel\n",
    "# from pathlib import Path\n",
    "# from openalex_search.db import init, ENGINE\n",
    "# from openalex_search.ingest import ingest\n",
    "\n",
    "# SQLModel.metadata.drop_all(ENGINE)\n",
    "# init()\n",
    "# ingest(Path(\"local_data/test_authors.parquet\"))\n",
    "# ingest(Path(\"local_data/test_articles.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
